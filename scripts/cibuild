#!/bin/bash

set -e

cmd_bootstrap () {
  go mod vendor
  (
    cd ./pkg/cuemodule/core/cue.mod
    cue get go github.com/greymatter-io/operator/api/...
    cue get go k8s.io/api/...
  )

  git submodule update --init --recursive --remote
}

# Runs go tests
cmd_test () {
  ./scripts/test lint
  ./scripts/test
}

# Polls the ec2 for k3s ready state
cmd_wait_for_k3s () {
  set +e #allow errors temporarily
  echo "Waiting for k3s to become available"
  while true; do
    echo "trying k3s..."
    k3s kubectl get nodes
    local exit_code=$?
    if [ "$exit_code" -eq 0 ]; then
      break
    else
      sleep 5
    fi
  done
  set -e
}

# Creates image secrets inside k3s cluster
cmd_create_secrets () {
  set -u
  local name=$1
  local ns=$2

  # Image pull secret
  k3s kubectl create secret docker-registry $name \
    --docker-server=quay.io \
    --docker-username="$QUAY_USERNAME" \
    --docker-password="$QUAY_PASSWORD" \
    -n $ns

  # SSH key secret for GitOps
  k3s kubectl create secret generic greymatter-sync-secret \
    --from-file=id_ed25519=$HOME/.ssh/id_ed25519 \
    -n $ns

  k3s kubectl create secret generic bugsnag-api-token \
  --from-literal=token="$BUGSNAG_API_TOKEN" \
  -n $ns

  set +u
}

# Builds docker image
cmd_build () {
  ./scripts/build container
  _build_manifests
}

cmd_build_debug () {
  ./scripts/build debug_container
}

_build_manifests () {
  ./scripts/build manifests
}

# Logs into Nexus, checks if CI is running during a tag release or merge into main and if so pushes assets. 
# Needs to download the previous assets in case the agent machine gets reassigned (in which case the build assets won't be there)
_release_container () {
  local buildkite_tag="${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}"
  local image_name="quay.io/greymatterio/operator"

  local latest="$image_name:latest"
  local intermediate="$image_name:$buildkite_tag"

  local debug_latest="$image_name:debug-latest"
  local debug_intermediate="$image_name:debug-$buildkite_tag"

  buildkite-agent artifact download "${buildkite_tag}.tar" . --build ${BUILDKITE_BUILD_ID} --agent-access-token ${BUILDKITE_AGENT_ACCESS_TOKEN}
  buildkite-agent artifact download "${buildkite_tag}_debug.tar" . --build ${BUILDKITE_BUILD_ID} --agent-access-token ${BUILDKITE_AGENT_ACCESS_TOKEN}

  podman load -q -i "${buildkite_tag}.tar"
  podman load -q -i "${buildkite_tag}_debug.tar"

  container-retag-image $intermediate $latest
  container-retag-image $debug_intermediate $debug_latest

  container-registry-login "$QUAY_USERNAME" "$QUAY_PASSWORD" quay.io
  if [[ "$BUILDKITE_BRANCH" == "main" ]]; then
    container-registry-push $latest
    container-registry-push $debug_latest
  fi
  if [[ -n "$BUILDKITE_TAG" ]]; then
    local tagged="quay.io/greymatterio/operator:${BUILDKITE_TAG:1}"
    local debug_tagged="quay.io/greymatterio/operator:debug-${BUILDKITE_TAG:1}"

    container-retag-image $latest $tagged
    container-registry-push $tagged

    container-retag-image $debug_latest $debug_tagged
    container-registry-push $debug_tagged
  fi
}

# Exports re-tagged docker image into tar with name ${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}[_OPTIONAL_SUFFIX]
# Tag test operator image with Buildkite env vars (Coleman):
# This avoids a failure mode where if the path-activated systemd service at /opt/k3s-import fails, our integration tests will fail in a more obvious way. Relying on "latest", as usual, is bad.
cmd_export_container () {
  local image=$1
  local export_suffix=$2
  local tag="${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}"
  local intermediate="quay.io/greymatterio/operator:$tag"
  local tarball=$tag

  if [ -n "$export_suffix" ]; then
    intermediate="${intermediate}_${export_suffix}"
    tarball="${tarball}_${export_suffix}"
  fi

  tarball="${tarball}.tar"

  container-retag-image $image $intermediate
  podman save --quiet -o $tarball $intermediate
  buildkite-agent artifact upload $tarball
}

# Exports a tarball of generated manifests
cmd_export_manifests () {
  local tarball=$1
  tar -czvf $tarball manifests/
  buildkite-agent artifact upload $tarball
}

# Build and push an OLM-compatible image of manifests for easy
# installation in OpenShift cluster contexts.
_release_bundle() {
  if [[ -n "$BUILDKITE_TAG" ]]; then
    local version=${BUILDKITE_TAG:1}
    sed -i "s/SEMVER_VERSION/${version}/" config/olm/manifests/kustomization.yaml
    kubectl kustomize config/olm/manifests | operator-sdk generate bundle -q \
      --package gm-operator --overwrite --version ${version}
    operator-sdk bundle validate ./bundle
    _build_image "docker.greymatter.io/development/gm-operator-bundle:${version}" bundle.Dockerfile
    container-registry-push "docker.greymatter.io/development/gm-operator-bundle:${version}"
  fi
}

# Creates the dynamic pipeline that starts up the greymatter mesh environment
#  in the ephemeral ec2s. The output of the echo commands runs on the ec2, not the original machine running the rest of the pipeline.
cmd_generate_integration_tests () {
  declare steps_yaml
  cases=('default' 'with_spire')

  for C in "${cases[@]}"; do
    launch_cluster $C
    steps_yaml+=("""
  - label: \"integration test: $C\"
    commands:
      - git submodule update --init --recursive --remote
      - scripts/cibuild wait_for_k3s
      - buildkite-agent artifact download \"${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}_debug.tar\" /tmp/
      - mv /tmp/\"${BUILDKITE_PIPELINE_SLUG}_${BUILDKITE_BUILD_NUMBER}_debug.tar\" /opt/k3s-import/
      - k3s kubectl create namespace gm-operator
      - scripts/cibuild create_secrets gm-docker-secret gm-operator
      - sleep 5
      - KUBECTL_CMD='k3s kubectl' ./scripts/test integration $C
      - k3s kubectl get pods -A
      - sudo systemctl poweroff
    agents:
      buildkite_build_number: $BUILDKITE_BUILD_NUMBER
      buildkite_pipeline_slug: $BUILDKITE_PIPELINE_SLUG
      integration_test_case: $C""")
  done
  echo "
steps: ${steps_yaml[@]}
  " | buildkite-agent pipeline upload
}

# Sends a POST request to a relay.sh webhook which triggers a process to spin up k3s cluster running on an ec2
launch_cluster () {
  # The tags payload will set EC2 tags that should be picked up by buildkite-agent
  # running in the new EC2.
  test_case=$1
  curl -sSL -X POST \
    -d "{ \"tags\": { \"buildkite_pipeline_slug\": \"$BUILDKITE_PIPELINE_SLUG\", \"buildkite_build_number\": \"$BUILDKITE_BUILD_NUMBER\", \"integration_test_case\": \"$test_case\"}}" \
    "$RELAYSH_LAUNCH_K3S_EC2_WEBHOOK"
}

# Releases the docker iamge and binaries if pipeline is running in the correct context
cmd_release () {
  _release_container
  _release_bundle
}

if [ $# -lt 1 ]
then
  echo "cibuild: missing argument"
  exit 1
fi

CMD=$1
shift
case $CMD in
  test|build|build_debug|release|generate_integration_tests|wait_for_k3s|export_container|export_manifests|create_secrets|bootstrap)
    cmd_$CMD $@
    ;;
  *)
    echo "invalid argument $1"
    exit 1
    ;;
esac
